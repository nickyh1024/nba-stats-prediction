{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90a67894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Original dataset shape: (3862, 112)\n",
      "Unique players: 1188\n",
      "Seasons covered: [2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "\n",
      "Missing data analysis:\n",
      "  3P%_prev5: 3479 (90.08%)\n",
      "  FT%_prev5: 3465 (89.72%)\n",
      "  TRB_prev5: 3463 (89.67%)\n",
      "  STL_prev5: 3463 (89.67%)\n",
      "  AST_prev5: 3463 (89.67%)\n",
      "  TOV_prev5: 3463 (89.67%)\n",
      "  3P_prev5: 3463 (89.67%)\n",
      "  3PA_prev5: 3463 (89.67%)\n",
      "  MP_prev5: 3463 (89.67%)\n",
      "  BLK_prev5: 3463 (89.67%)\n",
      "\n",
      "Cleaning data...\n",
      "\n",
      "Cleaned dataset shape: (3862, 109)\n",
      "Columns in cleaned dataset: 109\n",
      "Cleaned dataset saved to: cleaned_nba_data.csv\n",
      "\n",
      "==================================================\n",
      "CLEANED DATA ANALYSIS\n",
      "==================================================\n",
      "Total records: 3862\n",
      "Unique players: 1188\n",
      "Seasons: [2018, 2019, 2020, 2021, 2022, 2023, 2024]\n",
      "\n",
      "Season distribution:\n",
      "  2018: 541 players\n",
      "  2019: 531 players\n",
      "  2020: 530 players\n",
      "  2021: 541 players\n",
      "  2022: 606 players\n",
      "  2023: 540 players\n",
      "  2024: 573 players\n",
      "\n",
      "Career length distribution:\n",
      "  1 seasons: 340 players\n",
      "  2 seasons: 228 players\n",
      "  3 seasons: 163 players\n",
      "  4 seasons: 109 players\n",
      "  5 seasons: 104 players\n",
      "  6 seasons: 87 players\n",
      "  7 seasons: 157 players\n",
      "\n",
      "Position distribution:\n",
      "  SG: 933 records\n",
      "  PF: 753 records\n",
      "  C: 729 records\n",
      "  PG: 722 records\n",
      "  SF: 718 records\n",
      "\n",
      "Sample records:\n",
      " player_name  season  age pos  PTS_current  PTS_prev1  seasons_played  career_season_number\n",
      "  A.J. Green    2023 23.0  SG        154.0        NaN               2                     1\n",
      "  A.J. Green    2024 24.0  SG        252.0      154.0               2                     2\n",
      " A.J. Lawson    2023 22.0  SG         56.0        NaN               2                     1\n",
      " A.J. Lawson    2024 23.0  SG        136.0       56.0               2                     2\n",
      "  AJ Griffin    2023 19.0  SF        639.0        NaN               2                     1\n",
      "  AJ Griffin    2024 20.0  SF         48.0      639.0               2                     2\n",
      "Aaron Brooks    2018 33.0  PG         75.0        NaN               1                     1\n",
      "Aaron Gordon    2018 22.0  PF       1022.0        NaN               7                     1\n",
      "Aaron Gordon    2019 23.0  PF       1246.0     1022.0               7                     2\n",
      "Aaron Gordon    2020 24.0  PF        894.0     1246.0               7                     3\n",
      "\n",
      "Creating additional features...\n",
      "Added features. New shape: (3862, 164)\n",
      "\n",
      "Enhanced dataset saved to: enhanced_nba_data.csv\n",
      "\n",
      "Final columns (164):\n",
      "   1. player_id\n",
      "   2. player_name\n",
      "   3. season\n",
      "   4. age\n",
      "   5. pos\n",
      "   6. seasons_played\n",
      "   7. career_season_number\n",
      "   8. MP_current\n",
      "   9. PTS_current\n",
      "  10. TRB_current\n",
      "  11. AST_current\n",
      "  12. STL_current\n",
      "  13. BLK_current\n",
      "  14. TOV_current\n",
      "  15. FG%_current\n",
      "  16. 3P_current\n",
      "  17. 3PA_current\n",
      "  18. 3P%_current\n",
      "  19. FT%_current\n",
      "  20. FGA_current\n",
      "  21. FTA_current\n",
      "  22. ORB_current\n",
      "  23. DRB_current\n",
      "  24. PF_current\n",
      "  25. MP_prev1\n",
      "  26. PTS_prev1\n",
      "  27. TRB_prev1\n",
      "  28. AST_prev1\n",
      "  29. STL_prev1\n",
      "  30. BLK_prev1\n",
      "  31. TOV_prev1\n",
      "  32. FG%_prev1\n",
      "  33. 3P_prev1\n",
      "  34. 3PA_prev1\n",
      "  35. 3P%_prev1\n",
      "  36. FT%_prev1\n",
      "  37. FGA_prev1\n",
      "  38. FTA_prev1\n",
      "  39. ORB_prev1\n",
      "  40. DRB_prev1\n",
      "  41. PF_prev1\n",
      "  42. MP_prev2\n",
      "  43. PTS_prev2\n",
      "  44. TRB_prev2\n",
      "  45. AST_prev2\n",
      "  46. STL_prev2\n",
      "  47. BLK_prev2\n",
      "  48. TOV_prev2\n",
      "  49. FG%_prev2\n",
      "  50. 3P_prev2\n",
      "  51. 3PA_prev2\n",
      "  52. 3P%_prev2\n",
      "  53. FT%_prev2\n",
      "  54. FGA_prev2\n",
      "  55. FTA_prev2\n",
      "  56. ORB_prev2\n",
      "  57. DRB_prev2\n",
      "  58. PF_prev2\n",
      "  59. MP_prev3\n",
      "  60. PTS_prev3\n",
      "  61. TRB_prev3\n",
      "  62. AST_prev3\n",
      "  63. STL_prev3\n",
      "  64. BLK_prev3\n",
      "  65. TOV_prev3\n",
      "  66. FG%_prev3\n",
      "  67. 3P_prev3\n",
      "  68. 3PA_prev3\n",
      "  69. 3P%_prev3\n",
      "  70. FT%_prev3\n",
      "  71. FGA_prev3\n",
      "  72. FTA_prev3\n",
      "  73. ORB_prev3\n",
      "  74. DRB_prev3\n",
      "  75. PF_prev3\n",
      "  76. MP_prev4\n",
      "  77. PTS_prev4\n",
      "  78. TRB_prev4\n",
      "  79. AST_prev4\n",
      "  80. STL_prev4\n",
      "  81. BLK_prev4\n",
      "  82. TOV_prev4\n",
      "  83. FG%_prev4\n",
      "  84. 3P_prev4\n",
      "  85. 3PA_prev4\n",
      "  86. 3P%_prev4\n",
      "  87. FT%_prev4\n",
      "  88. FGA_prev4\n",
      "  89. FTA_prev4\n",
      "  90. ORB_prev4\n",
      "  91. DRB_prev4\n",
      "  92. PF_prev4\n",
      "  93. MP_prev5\n",
      "  94. PTS_prev5\n",
      "  95. TRB_prev5\n",
      "  96. AST_prev5\n",
      "  97. STL_prev5\n",
      "  98. BLK_prev5\n",
      "  99. TOV_prev5\n",
      "  100. FG%_prev5\n",
      "  101. 3P_prev5\n",
      "  102. 3PA_prev5\n",
      "  103. 3P%_prev5\n",
      "  104. FT%_prev5\n",
      "  105. FGA_prev5\n",
      "  106. FTA_prev5\n",
      "  107. ORB_prev5\n",
      "  108. DRB_prev5\n",
      "  109. PF_prev5\n",
      "  110. MP_career_avg\n",
      "  111. MP_last_season\n",
      "  112. MP_trend\n",
      "  113. PTS_career_avg\n",
      "  114. PTS_last_season\n",
      "  115. PTS_trend\n",
      "  116. TRB_career_avg\n",
      "  117. TRB_last_season\n",
      "  118. TRB_trend\n",
      "  119. AST_career_avg\n",
      "  120. AST_last_season\n",
      "  121. AST_trend\n",
      "  122. STL_career_avg\n",
      "  123. STL_last_season\n",
      "  124. STL_trend\n",
      "  125. BLK_career_avg\n",
      "  126. BLK_last_season\n",
      "  127. BLK_trend\n",
      "  128. TOV_career_avg\n",
      "  129. TOV_last_season\n",
      "  130. TOV_trend\n",
      "  131. FG%_career_avg\n",
      "  132. FG%_last_season\n",
      "  133. FG%_trend\n",
      "  134. 3P_career_avg\n",
      "  135. 3P_last_season\n",
      "  136. 3P_trend\n",
      "  137. 3PA_career_avg\n",
      "  138. 3PA_last_season\n",
      "  139. 3PA_trend\n",
      "  140. 3P%_career_avg\n",
      "  141. 3P%_last_season\n",
      "  142. 3P%_trend\n",
      "  143. FT%_career_avg\n",
      "  144. FT%_last_season\n",
      "  145. FT%_trend\n",
      "  146. FGA_career_avg\n",
      "  147. FGA_last_season\n",
      "  148. FGA_trend\n",
      "  149. FTA_career_avg\n",
      "  150. FTA_last_season\n",
      "  151. FTA_trend\n",
      "  152. ORB_career_avg\n",
      "  153. ORB_last_season\n",
      "  154. ORB_trend\n",
      "  155. DRB_career_avg\n",
      "  156. DRB_last_season\n",
      "  157. DRB_trend\n",
      "  158. PF_career_avg\n",
      "  159. PF_last_season\n",
      "  160. PF_trend\n",
      "  161. age_squared\n",
      "  162. is_rookie\n",
      "  163. is_veteran\n",
      "  164. years_experience\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "def clean_nba_data(input_file_path, output_file_path=None):\n",
    "    \"\"\"\n",
    "    Clean NBA dataset for prediction modeling\n",
    "    \n",
    "    Parameters:\n",
    "    input_file_path (str): Path to the input CSV file\n",
    "    output_file_path (str): Path to save cleaned data (optional)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Cleaned dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the data\n",
    "    print(\"Loading data...\")\n",
    "    df = pd.read_csv(input_file_path)\n",
    "    \n",
    "    # Display basic info about the dataset\n",
    "    print(f\"Original dataset shape: {df.shape}\")\n",
    "    print(f\"Unique players: {df['player_name'].nunique()}\")\n",
    "    print(f\"Seasons covered: {sorted(df['season'].unique())}\")\n",
    "    \n",
    "    # Analyze missing data\n",
    "    print(\"\\nMissing data analysis:\")\n",
    "    missing_data = df.isnull().sum()\n",
    "    missing_data = missing_data[missing_data > 0].sort_values(ascending=False)\n",
    "    for col, missing in missing_data.head(10).items():\n",
    "        percentage = (missing / len(df)) * 100\n",
    "        print(f\"  {col}: {missing} ({percentage:.2f}%)\")\n",
    "    \n",
    "    # Define stat columns\n",
    "    stat_columns = ['MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'FG%', \n",
    "                   '3P', '3PA', '3P%', 'FT%', 'FGA', 'FTA', 'ORB', 'DRB', 'PF']\n",
    "    \n",
    "    # Group by player and process\n",
    "    print(\"\\nCleaning data...\")\n",
    "    cleaned_records = []\n",
    "    \n",
    "    for player_name in df['player_name'].unique():\n",
    "        player_data = df[df['player_name'] == player_name].sort_values('season').reset_index(drop=True)\n",
    "        seasons_played = len(player_data)\n",
    "        \n",
    "        for idx, row in player_data.iterrows():\n",
    "            clean_record = {\n",
    "                'player_id': row['player_id'],\n",
    "                'player_name': row['player_name'],\n",
    "                'season': row['season'],\n",
    "                'age': row['age'],\n",
    "                'pos': row['pos'],\n",
    "                'seasons_played': seasons_played,\n",
    "                'career_season_number': idx + 1\n",
    "            }\n",
    "            \n",
    "            # Add current season stats (from \"next\" columns)\n",
    "            for stat in stat_columns:\n",
    "                clean_record[f'{stat}_current'] = row.get(f'{stat}_next', np.nan)\n",
    "            \n",
    "            # Add historical stats (prev1 through prev5)\n",
    "            for i in range(1, 6):\n",
    "                has_prev_data = row.get(f'has_prev{i}', 0)\n",
    "                for stat in stat_columns:\n",
    "                    if has_prev_data:\n",
    "                        clean_record[f'{stat}_prev{i}'] = row.get(f'{stat}_prev{i}', np.nan)\n",
    "                    else:\n",
    "                        clean_record[f'{stat}_prev{i}'] = np.nan\n",
    "            \n",
    "            cleaned_records.append(clean_record)\n",
    "    \n",
    "    # Create cleaned DataFrame\n",
    "    cleaned_df = pd.DataFrame(cleaned_records)\n",
    "    \n",
    "    print(f\"\\nCleaned dataset shape: {cleaned_df.shape}\")\n",
    "    print(f\"Columns in cleaned dataset: {len(cleaned_df.columns)}\")\n",
    "    \n",
    "    # Save if output path provided\n",
    "    if output_file_path:\n",
    "        cleaned_df.to_csv(output_file_path, index=False)\n",
    "        print(f\"Cleaned dataset saved to: {output_file_path}\")\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "def analyze_cleaned_data(df):\n",
    "    \"\"\"\n",
    "    Analyze the cleaned dataset\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"CLEANED DATA ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"Total records: {len(df)}\")\n",
    "    print(f\"Unique players: {df['player_name'].nunique()}\")\n",
    "    print(f\"Seasons: {sorted(df['season'].unique())}\")\n",
    "    \n",
    "    # Season distribution\n",
    "    print(f\"\\nSeason distribution:\")\n",
    "    season_counts = df['season'].value_counts().sort_index()\n",
    "    for season, count in season_counts.items():\n",
    "        print(f\"  {season}: {count} players\")\n",
    "    \n",
    "    # Career length distribution\n",
    "    print(f\"\\nCareer length distribution:\")\n",
    "    career_lengths = df['seasons_played'].value_counts().sort_index()\n",
    "    for length, count in career_lengths.items():\n",
    "        unique_players = df[df['seasons_played'] == length]['player_name'].nunique()\n",
    "        print(f\"  {length} seasons: {unique_players} players\")\n",
    "    \n",
    "    # Position distribution\n",
    "    print(f\"\\nPosition distribution:\")\n",
    "    pos_counts = df['pos'].value_counts()\n",
    "    for pos, count in pos_counts.items():\n",
    "        print(f\"  {pos}: {count} records\")\n",
    "    \n",
    "    # Sample records\n",
    "    print(f\"\\nSample records:\")\n",
    "    sample_cols = ['player_name', 'season', 'age', 'pos', 'PTS_current', 'PTS_prev1', 'seasons_played', 'career_season_number']\n",
    "    print(df[sample_cols].head(10).to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_features_for_prediction(df):\n",
    "    \"\"\"\n",
    "    Create additional features that might be useful for prediction\n",
    "    \"\"\"\n",
    "    print(\"\\nCreating additional features...\")\n",
    "    \n",
    "    # Calculate career averages (where data exists)\n",
    "    stat_columns = ['MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'TOV', 'FG%', \n",
    "                   '3P', '3PA', '3P%', 'FT%', 'FGA', 'FTA', 'ORB', 'DRB', 'PF']\n",
    "    \n",
    "    for stat in stat_columns:\n",
    "        # Get all previous season columns for this stat\n",
    "        prev_cols = [f'{stat}_prev{i}' for i in range(1, 6)]\n",
    "        \n",
    "        # Calculate career average (excluding NaN)\n",
    "        df[f'{stat}_career_avg'] = df[prev_cols].mean(axis=1, skipna=True)\n",
    "        \n",
    "        # Calculate most recent season (prev1 if available, else NaN)\n",
    "        df[f'{stat}_last_season'] = df[f'{stat}_prev1']\n",
    "        \n",
    "        # Calculate trend (difference between prev1 and prev2)\n",
    "        df[f'{stat}_trend'] = df[f'{stat}_prev1'] - df[f'{stat}_prev2']\n",
    "    \n",
    "    # Age-related features\n",
    "    df['age_squared'] = df['age'] ** 2\n",
    "    df['is_rookie'] = (df['career_season_number'] == 1).astype(int)\n",
    "    df['is_veteran'] = (df['career_season_number'] >= 5).astype(int)\n",
    "    \n",
    "    # Experience features\n",
    "    df['years_experience'] = df['career_season_number'] - 1\n",
    "    \n",
    "    print(f\"Added features. New shape: {df.shape}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your file paths here\n",
    "    input_file = \"../data/nba_dataset_5yr.csv\"  # Your input file\n",
    "    output_file = \"cleaned_nba_data.csv\"  # Output file\n",
    "    \n",
    "    try:\n",
    "        # Clean the data\n",
    "        cleaned_data = clean_nba_data(input_file, output_file)\n",
    "        \n",
    "        # Analyze the cleaned data\n",
    "        analyze_cleaned_data(cleaned_data)\n",
    "        \n",
    "        # Create additional features\n",
    "        enhanced_data = create_features_for_prediction(cleaned_data)\n",
    "        \n",
    "        # Save enhanced version\n",
    "        enhanced_output = \"enhanced_nba_data.csv\"\n",
    "        enhanced_data.to_csv(enhanced_output, index=False)\n",
    "        print(f\"\\nEnhanced dataset saved to: {enhanced_output}\")\n",
    "        \n",
    "        # Show final column list\n",
    "        print(f\"\\nFinal columns ({len(enhanced_data.columns)}):\")\n",
    "        for i, col in enumerate(enhanced_data.columns, 1):\n",
    "            print(f\"  {i:2d}. {col}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"Make sure your input file path is correct and the file exists.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "your_env_name",
   "language": "python",
   "name": "your_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
